---
layout: archive
# title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

## Professional Experience

### Senior AI/ML Engineer @ GSK (London)
  *September 2022 - Present*
  - Our team focuses on evaluation of LLMs and agent-based LLM-powered applications. ([GSKâ€™s JulesOS](https://www.gsk.ai/blogs/julesos-gsk-s-agent-based-operating-system/))  
  - We open-sourced our work on evaluating LLMs where our focus is on contextual knowledge. ([RAMBLA](https://github.com/GSK-AI/rambla))  
  - I previously worked on Out-of-distribution detection for Whole Slide Images.  

### Applied Scientist @ KidsLoop (Remote)
  *March 2022 - July 2022*
  - Part of the **recommender systems** (RecSys) team within the Applied Science team, working on models for structured representation of a learnerâ€™s knowledge (learner models / students models).  
  - Developing a learner model library to facilitate research in the field, with a focus on efficiency, extensibility, and experimental protocols. The ambition is for this to be used by data scientists, machine learning engineers, and to make it open source.  
  - Involved in designing experimental aspects and overseeing that the data science team implements best practices.  
  - **The company went into bankruptcy in July.**  

### Researcher @ Facebook (META) (FAIAR) (Remote)
  *Researcher (part-time) (PRO Unlimited Ltd) -- Nov. 2020 - Mar. 2021*  
  *Research intern (full-time) -- June 2020 - Oct. 2020*
  - Joined as an intern and was offered a contractor position afterward.  
  - Worked on **Computer Vision**, where I applied **Domain Generalisation** state-of-the-art techniques to emotion recognition across culture and age.  
  - Implemented and trained **large-scale** emotion recognition models to be used by the team.  
  - Implemented and compared several state-of-the-art methodologies for domain generalisation. ([arxiv paper ðŸ”—](#))  

### Researcher @ AXA Paris (R&D) (Remote & Paris)
  *Consultant (part-time) -- Oct. 2019 - June 2020*  
  *Research intern (full-time) -- Apr. 2019 - Sep. 2019*  
  - Joined as an intern and was offered a contractor position afterward. Left to join Facebook.  
  - Worked on **ML Interpretability**, with a focus on Local Surrogates for â€˜black-boxâ€™ machine learning models.  
  - **Developed in-house tools** to be used by researchers and data scientists for post-hoc model interpretability.  
  - Carried out research on understanding the current state-of-the-art on Local Surrogate Interpretability and eveloping new methodologies for it.  

Education
======
- **University of Bristol** *(Bristol, UK)*  
  *PhD*  
  *2017 â€“ 2022*  
  - **Thesis:** Inspecting the Machine Learning Pipeline: from Weak Supervision to Explainability  
  - **Supervisors:** Dr. Raul Santos-Rodriguez and Dr. Niall Twomey  
  - **Visits:** Spent 4 weeks at Ghent University, Belgium, hosted by Prof. Tijl De Bie to work on counterfactuals for machine learning interpretability.  
  - **Topics:** Machine Learning Interpretability/Explainability; Weak Supervision; Noisy labels; Behaviour Modelling for Healthcare  

- **University of Cambridge** *(Cambridge, UK)*  
  *MAST Mathematics (Part III); 69%*  
  *2016 â€“ 2017*  
  - **Units:** Modern Statistical Methods, Applied Statistics, Statistics in Medical Practice & Analysis of Survival Data, Mixing Times of Markov Chains, Topics in Convex Optimization, Bayesian Modelling and Computation  

- **University of Bristol** *(Bristol, UK)*  
  *BEng Engineering Mathematics; 80%*  
  *2013 â€“ 2016*  

Projects
========
- **LLM and agent evaluation**
  - We open-sourced our work on evaluating LLMs where our focus is on contextual knowledge. ([RAMBLA](https://github.com/GSK-AI/rambla))
- **Computer Vision**
  - (@Facebook) Worked on Domain Generalisation for emotion recognition, across age and culture. ([arxiv](https://arxiv.org/abs/2110.09168))
- **Weak Supervision (noisy labels, partial annotations)**
  - Presented a framework for categorising weak supervision settings based on a set of axes,
  - Developed novel techniques for label quality tests for labelled datasets,
  - Work on Label Proportions, as well as extensions to Ordinal Label Proportions.
- **ML Interpretability / Explainability**
  - Proposed a new direction for research on counterfactual explanations (FACE),
  - Presented new methodology for local surrogates,
  - (@AXA) developed in-house tools to be used by researchers and data scientists and carried out research on developing new methodologies for local surrogates.
  - Contributed an open-source python toolkit Fat Forensics â€œfor evaluating Fairness, Accountability and Transparency of Artificial Intelligence systemsâ€œ.